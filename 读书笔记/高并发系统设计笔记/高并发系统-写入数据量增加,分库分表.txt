1.单表带来的问题?
    当单表数据突破5千万,无论是数据库的查询还是写入性能都会下降。这时即使使用了索引,索引占用的空间也会随着数据量的
    增加而增大,数据库无法缓存全量的索引,那么就需要从磁盘上读取索引数据,就会影响到查询的性能。
2.单库带来的限制?
  单个库里面存储了不同业务模块的数据,数据量大时,主库一旦挂掉,各个模块都会导致不可用。

  单库写性能受限,4C8G MYSQL5.7 TPS 500。当业务量大时是扛不住的。

3.如何解决数据库的写入请求量大造成的性能和可用性方面的问题?
  分库分表

4.数据库垂直拆分
  垂直拆分，顾名思义就是对数据库竖着拆分，也就是将数据库的表拆分到多个不同的数据库中。
  垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。
  把不同的业务的数据分拆到不同的数据库节点上，这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能，
  从而实现了数据层面的故障隔离。

  垂直拆分还是不能解决,某一模块数据的暴增。此时需要对数据库做水平的拆分。

5.水平拆分
  拆分关注点:
       垂直拆分关注的是业务,不同的业务数据表拆分到不同的数据库中。
       水平拆分关注的是数据特点,单表数据量过大，按分区键将数据划分到不同的数据库,数据表。
  拆分规则:
        按照某一字段的hash值做拆分,这种拆分规则比较适用于实体表，比如说用户表，内容表，我们一般按照这些实体表的 ID 字段来拆分。
        比如说我们想把用户表拆分成 16 个库，每个库是 64 张表，那么可以先对用户 ID 做哈希，哈希的目的是将 ID 尽量打散，然后再对 16 取余，
        这样就得到了分库后的索引值；对 64 取余，就得到了分表后的索引值。

        按照某一字段的区间来拆分,比较常用的时间字段。按照时间去查询,汇总某些东西。此时可以按照时间字段去分库分表。
        比如说可以把一个月的数据放入一张表中，这样在查询时就可以根据创建时间先定位数据存储在哪个表里面，再按照查询条件来查询。
        一般来说，列表数据可以使用这种拆分方式，比如一个人一段时间的订单，一段时间发布的内容。但是这种方式可能会存在明显的热点，
        这很好理解嘛，你当然会更关注最近我买了什么，发了什么，所以查询的 QPS 也会更多一些，对性能有一定的影响。
        另外，使用这种拆分规则后，数据表要提前建立好。

6.分库分表引入的问题?
   分库分表引入的一个最大的问题就是引入了分库分表键，也叫做分区键，也就是我们对数据库做分库分表所依据的字段。

   我们之后所有的查询都需要带上这个字段，才能找到数据所在的库和表，否则就只能向所有的数据库和数据表发送查询命令。
   如果像上面说的要拆分成 16 个库和 64 张表，那么一次数据的查询会变成 16*64=1024 次查询，查询的性能肯定是极差的。

   解决上述问题:如何确定数据在哪个库表里面。
   例如,按ID分表,按昵称去查,这时怎么确定这个昵称在哪个库表呢?
   建立一个昵称和 ID 的映射表，在查询的时候要先通过昵称查询到 ID，再通过 ID 查询完整的数据，这个表也可以是分库分表的，
   也需要占用一定的存储空间，但是因为表中只有两个字段，所以相比重新做一次拆分还是会节省不少的空间的。

   数据count问题?将计数的数据单独存储在一张表中或者记录在 Redis 里面。

   如果一个订单库采用了买家id做为分区键，这样查询买家的订单非常容易，那要查询卖家的订单是不是和文中根据昵称查询一样，
   建立一个卖家和买家的映射表解决？
   订单ID分库分表，然后建立买家ID和卖家ID和订单ID的映射

7.分库分表解决的问题?
   经历过分库分表后的系统，才能够突破单机的容量和请求量的瓶颈，

8.分库分表经验
  1. 如果在性能上没有瓶颈点那么就尽量不做分库分表；
  2. 如果要做，就尽量一次到位，比如说 16 库，每个库 64 表就基本能够满足为了几年内你的业务的需求。
  3. 很多的 NoSQL 数据库，例如 Hbase，MongoDB 都提供 auto sharding 的特性，如果你的团队内部对于这些组件比较熟悉，
     有较强的运维能力，那么也可以考虑使用这些 NoSQL 数据库替代传统的关系型数据库

9.不停机迁移数据
  一般是先双写两个库，然后校验数据，然后灰度切读，最后全量切读