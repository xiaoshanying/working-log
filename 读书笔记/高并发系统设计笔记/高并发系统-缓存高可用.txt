1.架构
    web
    cache
    db(主从)
    web和db之间增加缓存,请求会先查询缓存
2.指标-缓存命中率
    r = 命中缓存的总请求数 / 总的请求数
    一般来说,电商系统中,核心的缓存命中率应该位置在99%左右。
    缓存命中率如果下降会对db产生较大压力

3.如何保证缓存节点高可用
    (1)为什么要保持高可用?
        假如缓存节点挂掉,10000qps进来,直接会将db负载打满,数据库连接池被打满,导致服务不可用。
    (2)分布式部署,单个节点出故障的概率是很高的

4.分布式缓存高可用方案-客户端方案
    (1)在客户端配置多个缓存节点,数据要写到哪个节点,由客户端代码控制
    (2)关注点
        写数据时:需要把写入缓存的数据分散到多个节点中,对数据进行分片
        读数据时:可以利用多组的缓存容错,提高可用性(主从,多副本)
    (3)数据如何分片?
        i:为何进行分片?有什么好处?
            单一的缓存节点会受,机器内存,网卡带宽,单节点请求量的限制,不能承担较高的并发.因此考虑将数据分片,
            依照分片算法将数据分散到各个节点上,每个节点只存储部分的数据
       ii:hash分片?
            node = hash(key) % n
            node指代算出来的结果,缓存最终存储的机器,n指代节点数量
            先对缓存key做crc32 hash,生成hash值,对节点总数取模得到最终的节点。
            这个算法最大的优点就是简单易理解，缺点是当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，
            从而造成缓存失效不可用(hash之后节点错误,导致找不到原先的缓存)
            采用这一种算法,要对缓存命中率下降有所容忍,最好可以有兜底策略
      iii:一致性hash分片?
            用一致性hash算法可以很好的解决节点删除,增加导致的缓存命中率下降的问题。
            原理:将hash值空间组成一个虚拟的圆环,将缓存节点的ip地址,或者主机名做hash取值后,放在圆环上。
            一个key过来,按上面的hash算法进行hash,确定在环上的位置,按顺时针方向在环上移动,遇到第一个节点
            就是要存储的节点。

            在增加和删除节点时，只有少量的 Key 会“漂移”到其它节点上，而大部分的 Key 命中的节点还是会保持不变，
            从而可以保证命中率不会大幅下降。

            存在的问题?
                缓存节点分布不均的话,一个节点失效会造成节点中的key瞬移到下个节点,对下个节点增加压力。
                    解决方案:虚节点,将一个节点计算多个hash值,分散到圆环上。实现数据的平均
                一致性hash算法可能带来脏数据问题
                    如何产生脏数据:a,b 客户端初始k存储到a中,这时如果要更新k的值,但是客户端和a连接出现问题
                    ,此时写请求会写入到b中。接下来a节点恢复,客户端取k得值时取得是a节点的老数据
                    解决方案:缓存加过期时间
            一般节点数
                4-6个
5.memcached主从机制
    架构
                client
    master      master     master
    slave       slave      slave

    每一个master配置一个slave,
        更新数据时主从同步更新
        读取数据时,优先从slave读。slave读不到,则去master读,然后会写到slave
    优点:
        slave宕机,还有master兜底,提升了缓存系统的可用性

6.多副本
    在master之前在增加一个副本层,来抵御热点请求。副本层节点容量比master和slave小,只存储更热的数据

7.缓存分布式高可用方案-中间代理层
    (1)客户端方案存在的问题?
        只能支持单一语言。
    (2)代理层解决的问题?
        可以实现多语言复用
    (3)方案
        自研:将客户端那一套高可用方案包装一下即可
        Mcrouter
        TwemProxy
        codis
    (4)原理
           client
     proxy   proxy  proxy
     redis   redis  redis
     所有缓存的读写请求都是经过代理层完成的。
     代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用的逻辑，不
     同的开源中间代理层方案中使用的高可用策略各有不同。
     比如在 Twemproxy 中，Proxy 保证在某一个 Redis 节点挂掉之后会把它从集群中移除，后续的请求将由其他节点来完成；
     而 Codis 的实现略复杂，它提供了一个叫 Codis Ha 的工具来实现自动从节点提主节点，
     在 3.2 版本之后换做了 Redis Sentinel 方式，从而实现 Redis 节点的高可用。

8.服务端方案
    Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题
    它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性
    Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，
    每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，
    Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，
    Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。
    Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，
    也就是集群内部需要对缓存节点的状态达成一致才行。（raft,paxos）

    Redis Sentinel 不属于代理层模式，因为对于缓存的写入和读取请求不会经过 Sentinel 节点。
    Sentinel 节点在架构上和主从是平级的，是作为管理者存在的，所以可以认为是在服务端提供的一种高可用方案。





